# ğŸŒ Earthquake Data Pipeline with Microsoft Fabric

This project demonstrates how to build a **fully automated data pipeline** using **Microsoft Fabric** and the **Medallion Architecture**. It ingests earthquake data from the **USGS API**, transforms it through Bronze â†’ Silver â†’ Gold layers, and visualises insights in **Power BI**. The pipeline is orchestrated using **Data Factory** and runs **daily**.

---

## ğŸ“Œ Business Case

Earthquake data is critical for:

* **Government agencies** â€“ supporting disaster response planning.
* **Researchers** â€“ analysing seismic activity trends.
* **Insurance companies** â€“ assessing regional risks.

This pipeline ensures stakeholders have **clean, enriched, and always up-to-date data** for informed decision-making.

---

## âš™ï¸ Solution Overview

We use Microsoft Fabric services to implement the **Medallion Architecture**:

1. **Bronze Layer** â€“ Ingest raw data from the USGS Earthquake API (GeoJSON).
2. **Silver Layer** â€“ Clean & structure data into **Delta tables** (time, magnitude, location, etc.).
3. **Gold Layer** â€“ Enrich with **country codes** (reverse geocoding) and **significance classifications**.
4. **Power BI Dashboard** â€“ Create interactive reports with maps, slicers, and KPIs.
5. **Data Factory Orchestration** â€“ Automate ingestion & processing on a **daily schedule**.

---

## ğŸ—ï¸ Architecture Diagram

![Medallion Architecture](images/architecture.png)

![Workflow](images/orchestration.png)
---

## ğŸš€ Features

* Automated **daily ingestion** of earthquake events.
* **JSON â†’ Delta tables** transformation using PySpark.
* Reverse geocoding to enrich data with **country codes**.
* **Significance classification** (Low, Moderate, High).
* Interactive **Power BI dashboard** with maps, KPIs & slicers.
* End-to-end automation via **Fabric Data Factory**.

---

## ğŸ“‚ Project Structure

```
earthquake-pipeline/
â”‚â”€â”€ notebooks/
â”‚   â”œâ”€â”€ Bronze-Layer-Processing.ipynb   # Fetch raw API data
â”‚   â”œâ”€â”€ Dilver-Layer-Processing.ipynb   # Transform JSON â†’ structured tables
â”‚   â”œâ”€â”€ Gold-Layer-Processing.ipynb    # Add country codes & classifications
â”‚â”€â”€ images/
â”‚   â”œâ”€â”€ architecture.png
â”‚   â”œâ”€â”€ orchestration.json
â”‚â”€â”€ README.md

```

---

## ğŸ”‘ Setup Instructions

### 1. Environment Setup

* Create a Microsoft **Work/School account**.
* Sign in to [Microsoft Fabric](https://app.fabric.microsoft.com/).
* Create a **Workspace** and a **Lakehouse**.

### 2. Bronze Layer (Raw Data)

* Create a **PySpark Notebook**.
* Fetch earthquake data using:

  * API: [USGS Earthquake API](https://earthquake.usgs.gov/fdsnws/event/1/)
* Save raw JSON in **Lakehouse Files**.

### 3. Silver Layer (Transformation)

* Load JSON into a Spark DataFrame.
* Extract required attributes (time, magnitude, location).
* Handle missing values & convert timestamps.
* Write output as **Silver Delta Table**.

### 4. Gold Layer (Enrichment)

* Install Python package: `reverse_geocoder`.
* Add **country codes** based on lat/lon.
* Add **significance classification**:

  * `<100 = Low`
  * `100â€“499 = Moderate`
  * `>=500 = High`
* Save as **Gold Delta Table**.

### 5. Power BI Dashboard

* Connect Power BI to the **Gold Table** via Fabric Semantic Model.
* Create visuals:

  * **Map** â†’ Country (location), Max Significance (bubble size), Classification (legend).
  * **Slicers** â†’ Date Range, Significance.
  * **KPIs** â†’ Total Events, Maximum Significance.

### 6. Data Factory Orchestration

* Create a **Pipeline** in Data Factory.
* Add notebooks in sequence: **Bronze â†’ Silver â†’ Gold**.
* Pass **dynamic dates**:

  * Start Date: `@formatDateTime(addDays(utcnow(), -1), 'yyyy-MM-dd')`
  * End Date: `@formatDateTime(utcnow(), 'yyyy-MM-dd')`
* Schedule **daily refresh**.

---

## ğŸ“Š Example Insights

* Daily **earthquake frequency by country**.
* **Magnitude vs significance** analysis.
* **Severity trend over time**.
* **High-risk regions visualised on map**.

---

## ğŸ› ï¸ Tech Stack

* **Microsoft Fabric** (Lakehouse, Data Factory, Power BI)
* **PySpark** (ETL & transformation)
* **reverse_geocoder** (location enrichment)
* **USGS Earthquake API** (data source)

---


---

## ğŸ™Œ Credits

* **Puneeth Kumar Amudala** â€“ Project design & implementation
* **Microsoft Fabric** â€“ Data platform services
* **USGS Earthquake API** â€“ Open seismic data provider
* **reverse_geocoder** â€“ Python package for geolocation enrichment


## ğŸ™ Acknowledgement  

Special thanks to **AI Luke** for the detailed walkthrough and guidance on this project.


## âœ… Summary

This project delivers a **scalable and automated earthquake monitoring system**:

* End-to-end pipeline from raw ingestion to Power BI insights.
* Clean, enriched, and **daily refreshed** dataset.
* Visualisation layer for decision-makers to quickly interpret seismic activity.
* Built using the **Medallion Architecture** for reliability and scalability.
